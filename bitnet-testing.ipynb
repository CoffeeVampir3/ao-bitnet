{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efb9cee-03c1-4481-a0d4-952fe8f25f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch._prims_common as utils\n",
    "import torch.utils._pytree as pytree\n",
    "from torch.library import impl, Library\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "def down_size(size):\n",
    "    assert size[-1] % 4 == 0, f\"{size} last dim not divisible by four\"\n",
    "    return (*size[:-1], size[-1] // 4)\n",
    "\n",
    "def up_size(size):\n",
    "    return (*size[:-1], size[-1] * 4)\n",
    "\n",
    "def unpack_uint2(uint8_data) -> torch.Tensor:\n",
    "    \"\"\"Get the original weight from the normalized float weight format\"\"\"\n",
    "    # since we are using uint8 we will decode 4 entries per byte\n",
    "    shape = uint8_data.shape\n",
    "    first_elements = ((uint8_data >> 6) & 0b11).to(torch.uint8)\n",
    "    second_elements = ((uint8_data >> 4) & 0b11).to(torch.uint8)\n",
    "    third_elements = ((uint8_data >> 2) & 0b11).to(torch.uint8) \n",
    "    fourth_elements = (uint8_data & 0b11).to(torch.uint8)\n",
    "    return torch.stack([first_elements, second_elements, third_elements, fourth_elements], dim=-1).view(up_size(shape))\n",
    "\n",
    "def pack_uint2(uint8_data) -> torch.Tensor:\n",
    "    # converting to uint8 for operations\n",
    "    shape = uint8_data.shape\n",
    "    assert shape[-1] % 4 == 0\n",
    "    uint8_data = uint8_data.contiguous().view(-1)\n",
    "    packed_data = (uint8_data[::4] << 6 | uint8_data[1::4] << 4 | uint8_data[2::4] << 2 | uint8_data[3::4]).view(down_size(shape))\n",
    "    return packed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad1f9a0-dfb0-4db2-a165-b8cfca7d9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here for reference:\n",
    "def pack_uint4(uint8_data) -> torch.Tensor:\n",
    "    # converting to uint8 for operations\n",
    "    shape = uint8_data.shape\n",
    "    assert shape[-1] % 2 == 0\n",
    "    uint8_data = uint8_data.contiguous().view(-1)\n",
    "    return (uint8_data[::2] << 4 | uint8_data[1::2]).view(down_size(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908a58e1-94aa-4488-b187-a2ff75f89cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here for reference:\n",
    "def unpack_uint4(uint8_data) -> torch.Tensor:\n",
    "    \"\"\"Get the original weight from the normalized float weight format\"\"\"\n",
    "    # since we are using uint8 we will decode 2 entries per byte\n",
    "    # Shift elements down 4 and select out the bottom 4 bits\n",
    "    shape = uint8_data.shape\n",
    "    first_elements = (uint8_data >> 4).to(torch.uint8)\n",
    "    second_elements = (uint8_data & 0b1111).to(torch.uint8)\n",
    "    return torch.stack([first_elements, second_elements], dim=-1).view(up_size(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a579c3b8-12c8-4317-a4e5-17a9f9e9aaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "131072 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e958813-1870-4ac7-bd45-3404f752cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[1024, 16, 8] u8 n=131072 (0.1Mb) x∈[0, 2] μ=0.999 σ=0.815\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.randint(0, 3, (1024, 16, 8), dtype=torch.uint8)\n",
    "print(test_tensor)\n",
    "packed = pack_uint2(test_tensor)\n",
    "unpacked = unpack_uint2(packed)\n",
    "print(unpacked.allclose(test_tensor))\n",
    "assert(unpacked.allclose(test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fafe7586-6ef6-4bdf-afe6-085cee15f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundclip(x, a, b):\n",
    "    return torch.max(torch.tensor(a), torch.min(torch.tensor(b), torch.round(x)))\n",
    "\n",
    "def quantize_per_tensor_uint2_trinary(weights):\n",
    "    # Compute the average absolute value of the weight tensor\n",
    "    gamma = torch.mean(torch.abs(weights))\n",
    "    \n",
    "    # Scale the weight tensor by the average absolute value\n",
    "    scaled_weights = weights / (gamma + 1e-8)\n",
    "    \n",
    "    # Round each scaled weight to the nearest integer in {-1, 0, +1}\n",
    "    quantized_weights = roundclip(scaled_weights, -1, 1)\n",
    "\n",
    "    #Shift the distribution over by 1 so we can pack into a uint and not deal with signs\n",
    "    quantized_weights += 1.0\n",
    "    return quantized_weights.to(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ec4312-7daa-41f0-a800-2e629f8df43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[1024, 16, 8] n=131072 (0.5Mb) x∈[-250.000, 249.996] μ=-0.710 σ=144.426"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_layer = torch.rand(1024, 16, 8) * 500.0 - 250.0\n",
    "test_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2933046e-00a4-444c-b466-d31f7b861b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[1024, 16, 8] u8 n=131072 (0.1Mb) x∈[0, 2] μ=0.999 σ=0.867\n"
     ]
    }
   ],
   "source": [
    "quantized_fake_layer = quantize_per_tensor_uint2_trinary(test_layer)\n",
    "print(quantized_fake_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1827cde-001b-44c8-ae39-a2b9933f4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "packed = pack_uint2(quantized_fake_layer)\n",
    "unpacked = unpack_uint2(packed)\n",
    "print(unpacked.allclose(quantized_fake_layer))\n",
    "assert(unpacked.allclose(quantized_fake_layer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
