{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efb9cee-03c1-4481-a0d4-952fe8f25f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch._prims_common as utils\n",
    "import torch.utils._pytree as pytree\n",
    "from torch.library import impl, Library\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "def down_size(size):\n",
    "    assert size[-1] % 4 == 0, f\"{size} last dim not divisible by four\"\n",
    "    return (*size[:-1], size[-1] // 4)\n",
    "\n",
    "def up_size(size):\n",
    "    return (*size[:-1], size[-1] * 4)\n",
    "\n",
    "def unpack_uint2(uint8_data) -> torch.Tensor:\n",
    "    \"\"\"Get the original weight from the normalized float weight format\"\"\"\n",
    "    # since we are using uint8 we will decode 4 entries per byte\n",
    "    shape = uint8_data.shape\n",
    "    unpacked_data = torch.empty((*shape, 4), dtype=torch.uint8)\n",
    "\n",
    "    unpacked_data[..., 0] = (uint8_data >> 6) & 0b11\n",
    "    unpacked_data[..., 1] = (uint8_data >> 4) & 0b11\n",
    "    unpacked_data[..., 2] = (uint8_data >> 2) & 0b11\n",
    "    unpacked_data[..., 3] = uint8_data & 0b11\n",
    "    return unpacked_data.view(up_size(shape))\n",
    "\n",
    "def pack_uint2(uint8_data) -> torch.Tensor:\n",
    "    # converting to uint8 for operations\n",
    "    shape = uint8_data.shape\n",
    "    assert shape[-1] % 4 == 0\n",
    "    uint8_data = uint8_data.contiguous().view(-1)\n",
    "    packed_data = (uint8_data[::4] << 6 | uint8_data[1::4] << 4 | uint8_data[2::4] << 2 | uint8_data[3::4]).view(down_size(shape))\n",
    "    return packed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e958813-1870-4ac7-bd45-3404f752cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[1024, 16, 8] u8 n=131072 (0.1Mb) x∈[0, 2] μ=1.005 σ=0.816\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.randint(0, 3, (1024, 16, 8), dtype=torch.uint8)\n",
    "print(test_tensor)\n",
    "packed = pack_uint2(test_tensor)\n",
    "unpacked = unpack_uint2(packed)\n",
    "print(unpacked.allclose(test_tensor))\n",
    "assert(unpacked.allclose(test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fafe7586-6ef6-4bdf-afe6-085cee15f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundclip(x, a, b):\n",
    "    return torch.max(torch.tensor(a), torch.min(torch.tensor(b), torch.round(x)))\n",
    "\n",
    "def quantize_per_tensor_uint2_trinary(weights):\n",
    "    # Compute the average absolute value of the weight tensor\n",
    "    gamma = torch.mean(torch.abs(weights))\n",
    "    \n",
    "    # Scale the weight tensor by the average absolute value\n",
    "    scaled_weights = weights / (gamma + 1e-8)\n",
    "    \n",
    "    # Round each scaled weight to the nearest integer in {-1, 0, +1}\n",
    "    quantized_weights = roundclip(scaled_weights, -1, 1)\n",
    "\n",
    "    #Shift the distribution over by 1 so we can pack into a uint and not deal with signs\n",
    "    return quantized_weights.to(torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29ec4312-7daa-41f0-a800-2e629f8df43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[1024, 16, 8] n=131072 (0.5Mb) x∈[-249.991, 249.989] μ=-0.106 σ=144.461"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_layer = torch.rand(1024, 16, 8) * 500.0 - 250.0\n",
    "test_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2933046e-00a4-444c-b466-d31f7b861b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[1024, 16, 8] n=131072 (0.5Mb) x∈[-1.000, 1.000] μ=-0.001 σ=0.866\n"
     ]
    }
   ],
   "source": [
    "#Quantize our fake layer with bitnet method.\n",
    "original_fake_layer = quantize_per_tensor_uint2_trinary(test_layer)\n",
    "print(original_fake_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "023937b1-fcda-4b0f-a059-53c7b13b5e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[1024, 16, 8] u8 n=131072 (0.1Mb) x∈[0, 2] μ=0.999 σ=0.866\n"
     ]
    }
   ],
   "source": [
    "#Shift distribution from -1, 1 -> 0, 2 to we can use unsigned storage.\n",
    "shifted_fake_layer = (original_fake_layer + 1.0).to(torch.uint8)\n",
    "print(shifted_fake_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f233a414-fe5f-41a1-8e70-b8545b84a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_uint8_to_trinary(uint8_data) -> torch.Tensor:\n",
    "    \"\"\"Get the original weight from the normalized float weight format\"\"\"\n",
    "    # since we are using uint8 we will decode 4 entries per byte\n",
    "    shape = uint8_data.shape\n",
    "    unpacked_data = torch.empty((*shape, 4), dtype=torch.int8)\n",
    "\n",
    "    unpacked_data[..., 0] = ((uint8_data >> 6) & 0b11).to(torch.int8) - 1.0\n",
    "    unpacked_data[..., 1] = ((uint8_data >> 4) & 0b11).to(torch.int8) - 1.0\n",
    "    unpacked_data[..., 2] = ((uint8_data >> 2) & 0b11).to(torch.int8) - 1.0\n",
    "    unpacked_data[..., 3] = (uint8_data & 0b11).to(torch.int8) - 1.0\n",
    "    return unpacked_data.view(up_size(shape))\n",
    "\n",
    "def pack_uint2(uint8_data) -> torch.Tensor:\n",
    "    # converting to uint8 for operations\n",
    "    shape = uint8_data.shape\n",
    "    assert shape[-1] % 4 == 0\n",
    "    uint8_data = uint8_data.contiguous().view(-1)\n",
    "    packed_data = (uint8_data[::4] << 6 | uint8_data[1::4] << 4 | uint8_data[2::4] << 2 | uint8_data[3::4]).view(down_size(shape))\n",
    "    return packed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1827cde-001b-44c8-ae39-a2b9933f4e46",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Char",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m packed \u001b[38;5;241m=\u001b[39m pack_uint2(shifted_fake_layer)\n\u001b[0;32m----> 2\u001b[0m unpacked \u001b[38;5;241m=\u001b[39m \u001b[43munpack_uint8_to_trinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(unpacked)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(unpacked\u001b[38;5;241m.\u001b[39mdtype)\n",
      "Cell \u001b[0;32mIn[41], line 11\u001b[0m, in \u001b[0;36munpack_uint8_to_trinary\u001b[0;34m(uint8_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m unpacked_data[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m ((uint8_data \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0b11\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint8) \n\u001b[1;32m     10\u001b[0m unpacked_data[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m (uint8_data \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0b11\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint8)\n\u001b[0;32m---> 11\u001b[0m unpacked_data \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpacked_data\u001b[38;5;241m.\u001b[39mview(up_size(shape))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Char"
     ]
    }
   ],
   "source": [
    "packed = pack_uint2(shifted_fake_layer)\n",
    "unpacked = unpack_uint8_to_trinary(packed)\n",
    "print(unpacked)\n",
    "print(unpacked.dtype)\n",
    "print(unpacked.allclose(original_fake_layer))\n",
    "assert(unpacked.allclose(original_fake_layer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
